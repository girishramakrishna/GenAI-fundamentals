{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed671a9-a94c-477a-b10a-18dff8662950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0a471c-b5af-4330-96f9-2c007a81ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-16-FEB\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6802b36a-4b2b-41a5-a04e-eb843ad2c232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-16-FEB\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", \n",
    "                            cache_folder=r'D:\\AI-DATASETS\\07-Hugging-Face-Data\\sentence-transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd0b722-925c-4a6f-bec8-1f4f09e1f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode([\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2e66be-2bf7-4511-b819-450ee1da919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.6817, 0.0492],\n",
       "        [0.6817, 1.0000, 0.0421],\n",
       "        [0.0492, 0.0421, 1.0000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = model.similarity(embeddings, embeddings)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ba006-48ed-47dd-ba6a-18c9ec5e045e",
   "metadata": {},
   "source": [
    "#### Ex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0145f90-f8d1-4520-b077-4cb38a3eac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a SentenceTransformer model with the 'multi-qa-mpnet-base-cos-v1'\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1',\n",
    "                            cache_folder=r'D:\\AI-DATASETS\\07-Hugging-Face-Data\\sentence-transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687fe0db-e75b-4d54-98b6-79441a958726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a list of documents to generate embeddings for\n",
    "docs = [\n",
    "    \"Around 9 million people live in London\",\n",
    "    \"London is known for its financial district\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a90034-e51a-494d-80a4-fc27b4598669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf460a002e542a7bc43ee161bd43f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate vector embeddings for the documents\n",
    "doc_emb = model.encode(\n",
    "                docs, # Our documents (an iterable of strings)\n",
    "                batch_size=32, # Batch the embeddings by this size\n",
    "                show_progress_bar=True # Display a progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e81e6b-9ed5-485f-bdcc-846921015fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of the embeddings is (2, 768), indicating a length of 768 \n",
    "\n",
    "doc_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eac699-c531-4d4c-ba6c-5bb58dd76da1",
   "metadata": {},
   "source": [
    "#### Ex 03\n",
    "\n",
    "**Cross Encoders**\n",
    "\n",
    "`Similarity Calculation`: Cross Encoders calculate similarity scores by taking pairs of texts as input and directly computing their similarity. Unlike Sentence Transformers, which encode texts separately, Cross Encoders consider both texts simultaneously.\n",
    "\n",
    "`Performance`: Cross Encoders generally provide superior performance in terms of accuracy because they capture the interactions between the two texts more effectively. This makes them especially good for tasks where precise semantic matching is crucial.\n",
    "\n",
    "`Computational Cost`: Cross Encoders are often slower than Sentence Transformers because they need to process each pair of texts individually. This results in higher computational costs, especially when comparing many pairs of texts.\n",
    "\n",
    "`Use Case` - Re-ranking: Due to their higher computational cost, Cross Encoders are commonly used to re-rank the top-k results from a Sentence Transformer model. The typical workflow involves:\n",
    "\n",
    "    - Using a Sentence Transformer to encode a large corpus and quickly retrieve the top-k most similar texts.\n",
    "    - Applying a Cross Encoder to the top-k pairs to re-rank them more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c709c7a-5f0c-4dc1-aa94-062b6491447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a56fead-d2cb-4b8d-8a58-aaed83009261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f7dd51b3474e0dab62dc90ac5f0e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-16-FEB\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bhupe\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92abb25444f24dea820ab32f6e1b3b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785412042f2b4285847aebf340f5ee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d23532118274b37bb68f894564e141f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faef99e30c344b1a4d9e8e9d6748e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load a pre-trained CrossEncoder model\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e33482a6-818a-4856-a390-c1125c3c9ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.6071415, -4.320076 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Predict scores for a pair of sentences\n",
    "scores = model.predict([\n",
    "    (\"How many people live in Berlin?\", \"Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\"),\n",
    "    (\"How many people live in Berlin?\", \"Berlin is well known for its museums.\"),\n",
    "])\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb75d54-80e2-411b-922a-a47c237061cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Rank a list of passages for a query\n",
    "query = \"How many people live in Berlin?\"\n",
    "\n",
    "passages = [\n",
    "    \"Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\",\n",
    "    \"Berlin is well known for its museums.\",\n",
    "    \"In 2014, the city state Berlin had 37,368 live births (+6.6%), a record number since 1991.\",\n",
    "    \"The urban area of Berlin comprised about 4.1 million people in 2014, making it the seventh most populous urban area in the European Union.\",\n",
    "    \"The city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019\",\n",
    "    \"An estimated 300,000-420,000 Muslims reside in Berlin, making up about 8-11 percent of the population.\",\n",
    "    \"Berlin is subdivided into 12 boroughs or districts (Bezirke).\",\n",
    "    \"In 2015, the total labour force in Berlin was 1.85 million.\",\n",
    "    \"In 2013 around 600,000 Berliners were registered in one of the more than 2,300 sport and fitness clubs.\",\n",
    "    \"Berlin has a yearly total of about 135 million day visitors, which puts it in third place among the most-visited city destinations in the European Union.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652b44db-29a0-45c4-b333-6de366e1cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = model.rank(query, passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69309af1-06b1-42be-8647-236e702e4516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How many people live in Berlin?\n",
      "8.92\tThe urban area of Berlin comprised about 4.1 million people in 2014, making it the seventh most populous urban area in the European Union.\n",
      "8.61\tBerlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\n",
      "8.24\tAn estimated 300,000-420,000 Muslims reside in Berlin, making up about 8-11 percent of the population.\n",
      "7.60\tIn 2014, the city state Berlin had 37,368 live births (+6.6%), a record number since 1991.\n",
      "6.35\tIn 2013 around 600,000 Berliners were registered in one of the more than 2,300 sport and fitness clubs.\n",
      "5.42\tBerlin has a yearly total of about 135 million day visitors, which puts it in third place among the most-visited city destinations in the European Union.\n",
      "3.45\tIn 2015, the total labour force in Berlin was 1.85 million.\n",
      "0.33\tBerlin is subdivided into 12 boroughs or districts (Bezirke).\n",
      "-4.24\tThe city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019\n",
      "-4.32\tBerlin is well known for its museums.\n"
     ]
    }
   ],
   "source": [
    "# Print the scores\n",
    "print(\"Query:\", query)\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t{passages[rank['corpus_id']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69604b6-33d0-4c9c-9c49-92faeb77e097",
   "metadata": {},
   "source": [
    "#### Ex 04\n",
    "\n",
    "- Cross Encoder for re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7bd2c4d-5855-49a4-be04-06e72c3b4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2860f119-eda1-45ae-a507-2b2596cd05ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9760e14d9ed548548c6fbb8c9b4d1824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-16-FEB\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bhupe\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43942c502ad47d8ae512df2700245b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af80c087dc543e2a5e885d8cb28dcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3794b6563a4a3c8a23a50f19b43b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3ac05e331b4c62b79b46c179ca02d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b58e33f6e2b4ae2a6fb5e69dc9b6553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e4cba88d8447de88e374503e0f4ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7f1d0bebf5441f88052b0326a9969a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0b63cc27484439b8f72d8c546dc25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d06386de064996921403d0a504b3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bc2f1f715a47cea79361dd6e59ee5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a bi-encoder model for initial retrieval\n",
    "bi_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d89802c8-43a7-4656-917e-c9a4f71ac091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447697862ec941d4b3c51a9bb68362bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-16-FEB\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bhupe\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ad02f3c6f1466c8d0100bdd8db863f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20b31da052243f4ad8c9c81fd8c6a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45371abc2144271b0a1aa473437f5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4a4100755f420da8613258dbc8c6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a cross-encoder model for re-ranking\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69087ec0-fcfc-4890-a553-8d12ea239e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some sentences and a query\n",
    "sentences = [\"This is a sentence.\", \"This is another sentence.\", \"Yet another sentence.\"]\n",
    "query = \"What is this sentence?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9becacbf-b7e4-44fa-89dd-a21bcdc63af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentences using bi-encoder\n",
    "sentence_embeddings = bi_encoder.encode(sentences)\n",
    "query_embedding     = bi_encoder.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03202825-bbf0-4f47-8993-59c679a5323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6087, 0.6072, 0.5031])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarities with the query\n",
    "cosine_scores = util.pytorch_cos_sim(query_embedding, sentence_embeddings)[0]\n",
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92b19605-60df-449c-8191-821601784b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top-k most similar sentences\n",
    "top_k = min(3, len(sentences))\n",
    "top_k_indices = cosine_scores.topk(k=top_k)[1]\n",
    "top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f949e28-ee8f-42dc-88d9-534bf6c112d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pairs for the cross-encoder\n",
    "pairs = [[query, sentences[idx]] for idx in top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e012ba8-e909-47c8-b586-f0ac943bfa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-rank using cross-encoder\n",
    "cross_scores = cross_encoder.predict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6210f089-acf7-47ef-ab66-587bcfc5cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-ranked results:\n",
      "Sentence: This is a sentence., Score: 3.8629605770111084\n",
      "Sentence: This is another sentence., Score: 1.9956350326538086\n",
      "Sentence: Yet another sentence., Score: -2.280318260192871\n"
     ]
    }
   ],
   "source": [
    "# Combine indices and scores\n",
    "re_ranked_results = sorted(zip(top_k_indices, cross_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Re-ranked results:\")\n",
    "for idx, score in re_ranked_results:\n",
    "    print(f\"Sentence: {sentences[idx]}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d1f80-e837-461c-b9a5-f1f08b5d569f",
   "metadata": {},
   "source": [
    "Cross Encoders provide a powerful method for computing precise similarity scores between pairs of texts by leveraging the joint processing capabilities of transformer models. They offer higher accuracy for tasks requiring detailed interaction analysis but come with higher computational costs. \n",
    "\n",
    "Combining Cross Encoders with bi-encoders allows for efficient and effective retrieval and ranking, making them a valuable tool for various advanced NLP applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de03c41a-0fbf-4fa8-b69d-52e61097469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pairs of sentences\n",
    "sentence_pairs = [\n",
    "    (\"This is a good book.\", \"This book is really good.\"),\n",
    "    (\"The weather is nice today.\", \"It is raining heavily.\"),\n",
    "    (\"I love playing football.\", \"Soccer is my favorite sport.\"),\n",
    "    (\"She enjoys reading novels.\", \"He likes watching movies.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f352155-6c2d-4016-b694-67219397eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Pair: ('This is a good book.', 'This book is really good.')\n",
      "Similarity Score: 7.161910057067871\n",
      "\n",
      "Sentence Pair: ('The weather is nice today.', 'It is raining heavily.')\n",
      "Similarity Score: -5.041144847869873\n",
      "\n",
      "Sentence Pair: ('I love playing football.', 'Soccer is my favorite sport.')\n",
      "Similarity Score: 3.345524549484253\n",
      "\n",
      "Sentence Pair: ('She enjoys reading novels.', 'He likes watching movies.')\n",
      "Similarity Score: -7.894623756408691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity scores for each pair of sentences\n",
    "similarity_scores = cross_encoder.predict(sentence_pairs)\n",
    "\n",
    "# Print the results\n",
    "for pair, score in zip(sentence_pairs, similarity_scores):\n",
    "    print(f\"Sentence Pair: {pair}\")\n",
    "    print(f\"Similarity Score: {score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf10a1-bf1c-46aa-a54b-05183c5d1eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
